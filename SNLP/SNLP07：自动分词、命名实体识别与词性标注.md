# 1 汉语自动分词中的基本问题
## 1.1 汉语分词规范问题

## 1.2 歧义切分问题

- 交集型切分歧义：汉字串 AJB 称作交集型切分歧义，如果满足 AJ、JB 同时为词（A、J、B分别为汉字串），此时称汉字串 J 为交集串。（大学生：“大学”、“学生”）

- 链长：一个交集型切分歧义所拥有的交集串的集合称为交集串链，它的个数称为链长。（结合成分子：“结合”、“合成”、“成分”和“分子”均构成词，交集串的集合为｛合，成，分｝，因此，链长为3。）

- 组合型切分歧义：汉字串 AB 称作多义组合型切分歧义，如果满足 A、B、AB 同时为词。（“起身”）

- 多义组合型切分歧义：汉字串 AB 称作多义组合型切分歧义，如果满足 A、B、AB 同时为词；文本中至少存在一个上下文语境 C，在 C 的约束下，A、B 在语法和语义上都成立。

## 1.3 未登录词问题

- 新出现的普通词汇
- 专有名词
- 专业名词和研究领域名称

# 2 汉语分词方法

- 汉语自动分词的基本原则：
  - 语义上无法由组合成分直接相加而得到的字串应该合并为一个分词单位。(合并原则)（不管三七二十一）
  - 语类无法由组合成分直接得到的字串应该合并为一个分词单位。 (合并原则)
    - 字串的语法功能不符合组合规律（好吃）
    - 字串的内部结构不符合语法规律（游水）
  - 有明显分隔符标记的应该切分之，分隔标记指标点符号或一个词。(切分原则)（洗/ 了/ 个/ 澡）
  - 附着性语(词)素和前后词合并为一个分词单位(合并原则）（检查员）
  - 使用频率高或共现率高的字串尽量合并为一个分词单位 (合并原则)（关门）
  - 双音节加单音节的偏正式名词尽量合并为一个分词单位 (合并原则)（贫困线）
  - 双音节结构的偏正式动词应尽量合并为一个分词单位 (合并原则)（组建）
  - 内部结构复杂、合并起来过于冗长的词尽量切分(切分原则)
    - 词组带接尾词（太空/ 计划/ 室）
    - 动词带双音节结果补语（看/ 清楚）
    - 复杂结构(自来水/ 公司)
    - 正反问句(喜欢/ 不/ 喜欢)
    - 动宾结构、述补结构的动词带词缀时(写信/ 给)
    - 词组或句子的专名，多见于书面语，戏剧名、歌曲名等(鲸鱼/ 的/ 生/ 与/ 死)
    - 专名带普通名词(京沪/ 铁路)

## 2.1 N-最短路径方法
- 基本思想：根据词典，找出字串中所有可能的词，构造词语切分的有向无环图。每个词对应图中的一条有向边，并赋给相应的边长（权值）。然后针对该切分图，在起点到终点的所有路径中，求出长度值按严格升序排列（任意两个不同位置上的值一定不等，下同）依次为第1，第2，…，第i，…，第N（$N\geq 1$）的路径集合作为相应的粗分结果集。如果两条或两条以上路径长度相等，那么，他们的长度并列第i，都要列入粗分结果集，而且不影响其他路径的排列序号，最后的粗分结果集大小大于或等于N。

- 算法描述：
  设待切分字串 $S=c_1 c_2…c_n$，其中$c_i (i =1, 2, …, n)$ 为单个的字， n 为串的长度，$n\geq1$。建立一个节点数为n+1的切分有向无环图G，各节点编号依次为$V_0， V_1，V_2，…，V_n$。
  ![\[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-tyZms0gW-1612916413827)(D:\picture\image-20210207200415124.png)\]](https://img-blog.csdnimg.cn/20210210121028314.png#pic_center)

  (1) 相邻节点 $v_{k-1}, v_k $之间建立有向边 $<v_{k-1}, v_k>$，边对应的词默认为 $c_k( k =1, 2, …, n)$。
  
  (2) 如果$ w= c_ic_{i+1}…c_j(0<i<j\leq n)$ 是一个词，则节点$v_{i-1}, v_j $之间建立有向边 $<v_{i-1}, v_j>$，边对应的词为$w$。
  

![\[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-DLDoYF85-1612916413834)(D:\picture\image-20210207201025091.png)\]](https://img-blog.csdnimg.cn/20210210121041420.png#pic_center)


  (3) 重复步骤(2)，直到没有新路径(词序列)产生。

  (4) 从产生的所有路径中，选择路径最短的(词数最少的)作为最终分词结果。

- 输入句子“他说的确实在理”：

  ![<img src="D:\picture\image-20210207202033270.png" alt="image-20210207202033270" style="zoom:80%;" />](https://img-blog.csdnimg.cn/20210210121055524.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg1NzY4OA==,size_16,color_FFFFFF,t_70#pic_center)


## 2.2 基于词的 n 元语法模型的分词方法

- 基本思想：首先根据词典对句子进行简单匹配，找出所有可能的词典词，然后将他们和所有单个字作为节点，构造 n 元的切分词图，图中的节点表示可能的词候选，边表示路径，边上的n元概率表示代价，最后利用相关搜索算法从图中找到代价最小的路径作为最后的分词结果。

- 输入句子“研究生物学”：

  ![<img src="D:\picture\image-20210207202053503.png" alt="image-20210207202053503" style="zoom:80%;" />](https://img-blog.csdnimg.cn/20210210121108417.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg1NzY4OA==,size_16,color_FFFFFF,t_70#pic_center)


## 2.3 由字构成的汉语分词方法
将分词过程看作是字的分类问题。该方法认为，每个字在构造一个特定的词语时都占据着一个确定的构词位置(即词位)。假定每个字只有4个词位：词首(B)、词中(M)、词尾(E)和单独成(S)，那么，每个字归属一特定的词位。

## 2.4 基于词感知机算法的汉语分词方法

对于任意给定的一个输入句子，解码器每次读一个字，生成所有的候选词。生成候选词的方式有两种：

- 作为上一个候选末尾，与上一个候选词组合成一个新的候选词
- 作为下一个候选词的开始。

这种方式可以保证在解码过程中穷尽所有的分词候选。在解码的过程中，解码器维持两个列表：源列表和目标列表。开始时，两个列表都为空。解码器每读入一个字，就与源列表中的每个候选组合生成两个新的候选（合并为一个新的词或者作为下一个词的开始），并将新的候选词放入目标列表。当源列表中的候选都处理完成之后，将目标列表中的所有候选复制到源列表中，并清空目标列表。然后读入下一个字，如此循环往复直到句子结束。最后从源列表中可以获得最终的切分结果。

## 2.5 基于字的生成式模型和区分式模型相结合的汉语分词方法

### 2.5.1 生成(产生)式模型
- 基于词的ｎ元语法模型（生成式模型）
- 假设 o 是观察值，q 是模型。如果对p(o|q)进行建模,就是生成式模型。其基本思想是：首先建立样本的概率密度模型，再利用模型进行推理预测。要求已知样本无穷多或者尽可能地多。
- 基于词的生成模型更多地考虑了词汇之间以及词汇内部字与字之间的依存关系。
- 基于词的生成式模型对于集内词（词典词）的处理可以获得较好的性能表现，而对集外词（未登录词）的分词效果欠佳


### 2.5.2 判别(区分)式模型
- 基于字的序列标注模型（区分式模型）
- 如果对条件概率(后验概率) p(q|o)进行建模，就是判别式模型。基本思想是：有限样本条件下建立判别函数，不考虑样本的产生模型，直接研究预测模型。
- 基于字的区分模型有利于处理集外词
- 基于字的区分式模型对集外词的处理有较好的鲁棒性，对集内词的处理却难以获得很好的性能。

### 2.5.3 结合
- 将待切分字串的每个汉字用$[c, t]_i$ 替代， 以$[c, t]_I$ 作为基元，利用语言模型选取全局最优(生成式模型)。

  ![<img src="D:\picture\image-20210207204652312.png" alt="image-20210207204652312" style="zoom: 67%;" />](https://img-blog.csdnimg.cn/20210210121126302.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDg1NzY4OA==,size_16,color_FFFFFF,t_70#pic_center)


- 插值法把两种方法结合起来，充分结合了基于字的生成模型和基于字的区分式模型的优点。

  ![<img src="D:\picture\image-20210207204721921.png" alt="image-20210207204721921" style="zoom: 80%;" />](https://img-blog.csdnimg.cn/20210210121137298.png#pic_center)


## 2.6 分词方法比较

![<img src="D:\picture\image-20210208113804099.png" alt="image-20210208113804099" style="zoom:67%;" />](https://img-blog.csdnimg.cn/20210210121147920.png#pic_center)


- 正确率：测试结果中正确切分或标注的个数占系统所有输出结果的比例。假设系统输出N 个，其中，正确的结果为n个，那么，
  $$
  p=\frac{n}{N}\times 100\%
  $$
- 召回率(找回率)：测试结果中正确结果的个数占标准答案总数的比例。假设系统输出N 个结果,其中，正确的结果为 n个，而标准答案的个数为M 个，那么，
  $$
  p=\frac{n}{M}\times 100\%
  $$
  其中,$R_{OOV}$指集外词的召回率；$R_{IV}$指集内词的召回率。
- F-测度值：正确率与找回率的综合值。计算公式为：
  $$
  F=\frac{(\beta^2+1)\times P \times R}{\beta^2 \times P+R}\times 100\%
  $$
  一般地，取 $\beta = 1$，即
  $$
  F=\frac{2 \times P \times R}{P+R}\times 100\%
  $$

# 3 命名实体识别

## 3.1 方法概述

- 有监督的学习方法
  - 隐马尔可夫模型或语言
  - 最大熵模型
  - 支持向量机
  - 条件随机场
  - 决策树
- 半监督（弱监督）的学习方法
  - 利用标注的小数据集（种子数据）自举学习
- 无监督的学习方法
  - 利用词汇资源等进行上下文聚类
- 混合方法
  - 几种模型相结合或利用统计方法和人工总结的知识库

## 3.2 基于CRF的命名实体识别方法

- 基本思路：将给定的文本首先进行分词处理，然后对人名，简单地名和简单组织机构名进行识别，最后识别复合地名和复合机构名。
- 步骤：
  - 将分词语料的标记符号转化为用于命名实体序列标注的标记。
  - 确定模板特征
  - 训练 CRF 模型参数

## 3.3 基于多特征的命名实体识别方法

- 词形上下文模型 P(WC)
- 词性上下文模型 P(TC)
- 实体词形模型 P(W | WC)
- 实体词性模型 P(T | TC)

# 5 词性标注

## 5.1 概述

- 汉语是一种缺乏词形态变化的语言
- 常用词兼类现象严重
- 研究者主观原因造成的困难

## 5.2 基于统计模型的词性标注方法

- LOB语料库词性标注系统CLAWC：基于统计模型（n元语法与一阶马尔可夫转移矩阵）的词性标注方法。
- Jelinek方法：用最大似然估计来估算概率以及初始化HMM，并假设每个词与其每个可能的词性标注出现的概率相等。
- Kupiec方法：将词汇划分成若干等价类，以类为单位进行参数估计，避免了为每个单词单独调参，大大减少了参数的总个数。

## 5.3 基于规则的词性标注方法

- 按兼类词搭配关系和上下文语境建造词类消歧规则。

- 基于转换规则的错误驱动的学习方法：首先运用初始状态标注器标识未标注的文本，由此产生已标注的文本。文本一旦被标注以后，将其与正确的标注文本（参考答案）进行比较。由于初始标注器标注的文本一般会含有错误，学习器将这些标注文本与正确的标注文本相比较，可以学习到一些转换规则，从而形成一个排序的转换规则集，使其能够修正已标注的文本，使标注结果更接近参考答案。这样，在所有学习到的可能的转换规则中，搜索那些使已标注文本中的错误数减少最多的规则加人到规则集，并将该规则用于调整已标注的文本，然后对已标注的语料重新打分（统计错
  数）。不断重复该过程，直到没有新的转换规则能够使已标注的语料错误数减少。最终的转换规则集就是学习到转换规则结果。

## 5.4 统计方法与规则方法相结合的词性标注方法

句子的初始标注结果（每个词带有所有可能的词类标记），首先经过规则排歧，排除那些最常见的、语言现象比较明显的歧义现象，然后通过统计排歧，处理那些剩余的多类词并进行未登录词的词性推断，最后再进行人工校对，得到正确的标注结果。这样做有两好处∶一方面利用标注语料对统计模型进行参数训练，可以得到统计排歧所需要的不同参数;另一方面，通过将机器自动标注的结果（规则排歧的或统计排歧的）与人工校对结果进行比较，可以发现自动处理的错误所在，从中总结出大量有用的信息以补充和调整则库的内容。但其规则的作用域是非受限而且并没有考虑统计的可信度，这使规则与统计的作用域不明确。因此引入置信区间的方法，构造了一种基于置信区间的评价函数，实现了统计和规则并举。

## 5.5 词性标注中的生词处理方法

- 基于规则的词性标注方法：生词处理通常是与词形分析和兼类词歧义消解一起进行的。
- 基于统计模型的词性标注方法：生词的词性标注问题通常是通过合理处理词汇的发射率来解决的。