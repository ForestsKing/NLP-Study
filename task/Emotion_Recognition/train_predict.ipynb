{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_predict(3-11).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQOQTkMmMkRO"
      },
      "source": [
        "# 导包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Us0NI5SSLWiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1524414-d58f-49d0-f1b5-7ffc9b188227"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.nn import init\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data as Data\r\n",
        "\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "!pip install transformers\r\n",
        "import transformers\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "from tqdm import tqdm\r\n",
        "import csv\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DSc6CePNonz"
      },
      "source": [
        "# 定义超参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWNU4IxhNrMR"
      },
      "source": [
        "CFG = {\r\n",
        "    'fold_num': 5,\r\n",
        "    'seed': 2021,\r\n",
        "    'model': 'hfl/chinese-bert-wwm-ext', #预训练模型\r\n",
        "    'max_len': 100,\r\n",
        "    'lr': 0.001, #学习率\r\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\r\n",
        "    'n_class': 3,\r\n",
        "    'batch_size': 32,\r\n",
        "    'epochs': 1,\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyckOGPBOUhb"
      },
      "source": [
        "# 固定种子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaoZaTihOXfE"
      },
      "source": [
        "def seed_everything(seed):\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed_all(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "\r\n",
        "seed_everything(CFG['seed']) #固定随机种子"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPJb2dVSX4Ux"
      },
      "source": [
        "# 读取数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9uX97pUTsMr"
      },
      "source": [
        "train_df=pd.read_csv('/content/drive/MyDrive/data/Emotion_Recognition/nCoV_100k_train.labled.csv')\r\n",
        "test_df=pd.read_csv('/content/drive/MyDrive/data/Emotion_Recognition/nCov_10k_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGoTmTjJX75R"
      },
      "source": [
        "# 数据预处理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJAZsukRg0AT"
      },
      "source": [
        "## 输入转换"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oofPKXdgT4Qz"
      },
      "source": [
        "tokenizer=transformers.BertTokenizer.from_pretrained(CFG['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzvnC0RjXaeL"
      },
      "source": [
        "def convert_to_transformers_inputs(instance, tokenizer, max_len):\r\n",
        "    inputs = tokenizer.encode_plus(\r\n",
        "        instance,\r\n",
        "        add_special_tokens=True,\r\n",
        "        max_length=max_len,\r\n",
        "        truncation_strategy='longest_first'\r\n",
        "    )\r\n",
        "\r\n",
        "    input_ids = inputs['input_ids']\r\n",
        "    input_masks = inputs['attention_mask']\r\n",
        "    input_segments = inputs['token_type_ids']\r\n",
        "\r\n",
        "    # 填充\r\n",
        "    padding_len = max_len - len(input_ids)\r\n",
        "    padding_id = tokenizer.pad_token_id\r\n",
        "    input_ids = input_ids + ([padding_id] * padding_len)\r\n",
        "    input_masks = input_masks + ([0] * padding_len)\r\n",
        "    input_segments = input_segments + ([0] * padding_len) \r\n",
        "    return [input_ids, input_masks, input_segments]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU9CXD2TeJGJ"
      },
      "source": [
        "def compute_input_arrays(df, col, tokenizer, max_len):\r\n",
        "    input_ids, input_masks, input_segments = [], [], []\r\n",
        "    \r\n",
        "    for instance in tqdm(df[col]):\r\n",
        "        ids, masks, segments = convert_to_transformers_inputs(str(instance), tokenizer, max_len)\r\n",
        "        input_ids.append(ids)\r\n",
        "        input_masks.append(masks)\r\n",
        "        input_segments.append(segments)\r\n",
        "    \r\n",
        "    return [np.asarray(input_ids, dtype=np.int32), np.asarray(input_masks, dtype=np.int32), np.asarray(input_segments, dtype=np.int32)]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QNf9hPBfm2B",
        "outputId": "4e7d945d-d664-489d-aa97-49ce70a28d05"
      },
      "source": [
        "input_categories = '微博中文内容'\r\n",
        "output_categories = '情感倾向'\r\n",
        "inputs = compute_input_arrays(train_df, input_categories, tokenizer, CFG['max_len'])\r\n",
        "test_inputs = compute_input_arrays(test_df, input_categories, tokenizer, CFG['max_len'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/99913 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 99913/99913 [01:20<00:00, 1247.50it/s]\n",
            "100%|██████████| 10000/10000 [00:08<00:00, 1224.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf7PfjjgkmBZ"
      },
      "source": [
        "## 输出转换"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8joafqNXkoTZ"
      },
      "source": [
        "def compute_output_arrays(df, col):\r\n",
        "    # 从0开始。所以+1\r\n",
        "    return np.asarray(df[col].astype(int)+1)\r\n",
        "\r\n",
        "outputs = compute_output_arrays(train_df,output_categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiIS8eWBleG_"
      },
      "source": [
        "# Bert模型\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q73AMPLcnCxH"
      },
      "source": [
        "class TextNet(nn.Module):\r\n",
        "    def __init__(self): #code_length为fc映射到的维度大小\r\n",
        "        super(TextNet, self).__init__()\r\n",
        "\r\n",
        "        bert_config = transformers.BertConfig.from_pretrained(CFG['model'], output_hidden_states=True)\r\n",
        "        self.bert_model = transformers.BertModel.from_pretrained(CFG['model'], config=bert_config)\r\n",
        "        \r\n",
        "        embedding_dim = self.bert_model.config.hidden_size\r\n",
        "        self.fc = nn.Linear(embedding_dim, CFG['n_class'])        \r\n",
        "\r\n",
        "    def forward(self, ids, masks, segments):\r\n",
        "        output=self.bert_model(ids, attention_mask=masks, token_type_ids=segments)\r\n",
        "        text_embeddings = output[0][:, 0, :]  \r\n",
        "        #output[0](batch size, sequence length, model hidden dimension)\r\n",
        "\r\n",
        "        features = self.fc(text_embeddings)\r\n",
        "        return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkL0eUQKqwlf"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76qXgKylqv_6",
        "outputId": "1bb21a8a-0111-4c92-ed57-c4525c91eb39"
      },
      "source": [
        "folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed'])\\\r\n",
        "                    .split(train_df[input_categories].fillna('-1'), train_df[output_categories].fillna('-1')) #五折交叉验证\r\n",
        "for fold, (train_idx, valid_idx) in enumerate(folds):\r\n",
        "\r\n",
        "    train_inputs = torch.LongTensor([inputs[i][train_idx] for i in range(len(inputs))])\r\n",
        "    train_inputs = train_inputs.transpose(0, 1)\r\n",
        "    train_outputs = torch.LongTensor(outputs[train_idx])\r\n",
        "\r\n",
        "    valid_inputs = torch.LongTensor([inputs[i][valid_idx] for i in range(len(inputs))])\r\n",
        "    valid_inputs = valid_inputs.transpose(0, 1)\r\n",
        "    valid_outputs = torch.LongTensor(outputs[valid_idx])\r\n",
        "\r\n",
        "    train_dataset = Data.TensorDataset(train_inputs, train_outputs)\r\n",
        "    valid_dataset = Data.TensorDataset(valid_inputs, valid_outputs)\r\n",
        "    \r\n",
        "    train_loader = Data.DataLoader(train_dataset, CFG['batch_size'], True)\r\n",
        "    valid_loader = Data.DataLoader(valid_dataset, CFG['batch_size'], True)\r\n",
        "\r\n",
        "    model = TextNet().to(CFG['device'])\r\n",
        "    criterion = nn.CrossEntropyLoss().to(CFG['device'])\r\n",
        "    optimizer = optim.Adam(model.parameters(), lr=CFG['lr'])\r\n",
        "\r\n",
        "    for epoch in range(CFG['epochs']):\r\n",
        "        for batch_x, batch_y in tqdm(train_loader):\r\n",
        "            batch_x, batch_y = batch_x.to(CFG['device']), batch_y.to(CFG['device'])\r\n",
        "            ids, masks, segments = batch_x[:,0,:], batch_x[:,1,:], batch_x[:,2,:]\r\n",
        "\r\n",
        "            pred = model(ids, masks, segments)\r\n",
        "            loss = criterion(pred, batch_y)\r\n",
        "    \r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "        true = 0.0\r\n",
        "        all = 0.0\r\n",
        "    for batch_x, batch_y in tqdm(valid_loader):\r\n",
        "        batch_x, batch_y = batch_x.to(CFG['device']), batch_y.to(CFG['device'])\r\n",
        "        ids, masks, segments = batch_x[:,0,:], batch_x[:,1,:], batch_x[:,2,:]\r\n",
        "        pred_y = torch.max(model(ids, masks, segments), 1)[1].cpu().data.numpy()\r\n",
        "        real_y = batch_y.cpu().data.numpy()\r\n",
        "        true += float((pred_y == real_y).astype(int).sum())\r\n",
        "        all += float(len(real_y))\r\n",
        "    accuracy = true / all\r\n",
        "    print('fold: ', (fold+1), '| accuracy: %.4f' % accuracy)\r\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/data/Emotion_Recognition/tmp/fold_{}.pt'.format(fold))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2498/2498 [12:24<00:00,  3.35it/s]\n",
            "100%|██████████| 625/625 [01:01<00:00, 10.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold:  1 | accuracy: 0.5767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2498/2498 [12:25<00:00,  3.35it/s]\n",
            "100%|██████████| 625/625 [01:01<00:00, 10.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold:  2 | accuracy: 0.5767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2498/2498 [12:25<00:00,  3.35it/s]\n",
            "100%|██████████| 625/625 [01:01<00:00, 10.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold:  3 | accuracy: 0.5767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2498/2498 [12:24<00:00,  3.35it/s]\n",
            "100%|██████████| 625/625 [01:01<00:00, 10.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold:  4 | accuracy: 0.5767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2498/2498 [12:24<00:00,  3.35it/s]\n",
            "100%|██████████| 625/625 [01:01<00:00, 10.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fold:  5 | accuracy: 0.5767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzaNGxNs_XnV"
      },
      "source": [
        "# 预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpfmd_HbTtfR"
      },
      "source": [
        "test_inputs = torch.LongTensor(test_inputs)\r\n",
        "test_inputs = test_inputs.transpose(0, 1)\r\n",
        "test_dataset = Data.TensorDataset(test_inputs,)\r\n",
        "test_loader = Data.DataLoader(test_dataset, CFG['batch_size'], False)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTpPh7CEcIl6"
      },
      "source": [
        "\r\n",
        "model = TextNet().to(CFG['device'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2LpmpHw_Zi1",
        "outputId": "d8cf71fc-bd18-448e-bffd-7955bb358af1"
      },
      "source": [
        "pred_ys=[]\r\n",
        "for fold in range(CFG['fold_num']): #把训练后的五个模型挨个进行预测\r\n",
        "    pred_y = []\r\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/data/Emotion_Recognition/tmp/fold_{}.pt'.format(fold))) \r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        for batch_x, in tqdm(test_loader):\r\n",
        "            batch_x = batch_x.to(CFG['device'])\r\n",
        "            ids, masks, segments = batch_x[:,0,:], batch_x[:,1,:], batch_x[:,2,:]\r\n",
        "            output = model(ids, masks, segments)\r\n",
        "            pred_y.extend(output.cpu().detach().numpy().tolist())            \r\n",
        "    pred_ys.append(pred_y)\r\n",
        "pred_y = np.mean(pred_ys, axis=0)\r\n",
        "pred=np.argmax(pred_y,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:30<00:00, 10.11it/s]\n",
            "100%|██████████| 313/313 [00:30<00:00, 10.10it/s]\n",
            "100%|██████████| 313/313 [00:30<00:00, 10.13it/s]\n",
            "100%|██████████| 313/313 [00:30<00:00, 10.13it/s]\n",
            "100%|██████████| 313/313 [00:30<00:00, 10.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqjyVvdmesjy"
      },
      "source": [
        "headers=['测试数据id','情感极性']\r\n",
        "rows=[]\r\n",
        "for i,y in enumerate(pred):\r\n",
        "   rows.append([i,y-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZaY6BIRf3bf"
      },
      "source": [
        "with open('/content/drive/MyDrive/data/Emotion_Recognition/tmp/result.csv','w')as f:\r\n",
        "    f_csv = csv.writer(f)\r\n",
        "    f_csv.writerow(headers)\r\n",
        "    f_csv.writerows(rows)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}