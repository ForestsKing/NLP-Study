{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IE6b4n3ll_H"
      },
      "source": [
        "# 背景\r\n",
        "给定一个长句子预测下一个单词"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eUATgBllr-_"
      },
      "source": [
        "# 导包"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTtyb4RjlgGp"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data as Data\r\n",
        "\r\n",
        "dtype = torch.FloatTensor\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tALLK06lxZv"
      },
      "source": [
        "# 准备数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrzpyXQilwr8"
      },
      "source": [
        "sentence = (\r\n",
        "    'GitHub Actions makes it easy to automate all your software workflows '\r\n",
        "    'from continuous integration and delivery to issue triage and more'\r\n",
        ")\r\n",
        "# 其实就是个字符串，就是将上下两行字符串连接在一起的一个大字符串\r\n",
        "\r\n",
        "word2idx = {w: i for i, w in enumerate(list(set(sentence.split())))}\r\n",
        "idx2word = {i: w for i, w in enumerate(list(set(sentence.split())))}\r\n",
        "n_class = len(word2idx) # classification problem\r\n",
        "max_len = len(sentence.split())\r\n",
        "n_hidden = 5\r\n",
        "batch_size = 3"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C8XTPPbmGeG"
      },
      "source": [
        "# 数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfwAL23_mIqS"
      },
      "source": [
        "def make_data(sentence):\r\n",
        "    input_batch = []\r\n",
        "    target_batch = []\r\n",
        "\r\n",
        "    words = sentence.split()\r\n",
        "    for i in range(max_len - 1):\r\n",
        "        input = [word2idx[n] for n in words[:(i + 1)]]\r\n",
        "        input = input + [0] * (max_len - len(input)) # 用0填充，保证一样长\r\n",
        "        target = word2idx[words[i + 1]]\r\n",
        "        input_batch.append(np.eye(n_class)[input])\r\n",
        "        target_batch.append(target)\r\n",
        "\r\n",
        "    return torch.Tensor(input_batch), torch.LongTensor(target_batch)\r\n",
        "\r\n",
        "# input_batch: [max_len - 1, max_len, n_class]\r\n",
        "input_batch, target_batch = make_data(sentence)\r\n",
        "dataset = Data.TensorDataset(input_batch, target_batch)\r\n",
        "loader = Data.DataLoader(dataset, batch_size, True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R51sfRVjoJOK"
      },
      "source": [
        "# 定义网络架构\r\n",
        "## 构造\r\n",
        "- input_size – 输入数据的大小，也就是前面例子中每个单词向量的长度\r\n",
        "- hidden_size – 隐藏层的大小（即隐藏层节点数量），输出向量的维度等于隐藏节点数\r\n",
        "- num_layers – recurrent layer的数量，默认等于1。\r\n",
        "- bias – 网络是否设置偏置，默认是True.\r\n",
        "- batch_first – 默认为False，也就是说官方不推荐我们把batch放在第一维，这个CNN有点不同，此时输入输出的各个维度含义为 (seq_length,batch,feature)。当然如果你想和CNN一样把batch放在第一维，可将该参数设置为True。\r\n",
        "- dropout – 如果非0，就在除了最后一层的其它层都插入Dropout层，默认为0。\r\n",
        "- bidirectional – If True, becomes a bidirectional LSTM. Default: False\r\n",
        "\r\n",
        "## 输入\r\n",
        "input, (h_0,c_0)\r\n",
        "- input: 输入数据，即上面例子中的一个句子（或者一个batch的句子），其维度形状为 (seq_len, batch, input_size)\r\n",
        "  - seq_len: 句子长度，即单词数量，这个是需要固定的。当然假如你的一个句子中只有2个单词，但是要求输入10个单词，这个时候可以用torch.nn.utils.rnn.pack_padded_sequence()或者torch.nn.utils.rnn.pack_sequence()来对句子进行填充或者截断。\r\n",
        "  - batch：就是你一次传入的句子的数量\r\n",
        "  - input_size: 每个单词向量的长度，这个必须和你前面定义的网络结构保持一致\r\n",
        "- h_0：维度形状为 (num_layers * num_directions, batch, hidden_size):\r\n",
        "  - 结合下图应该比较好理解第一个参数的含义num_layers * num_directions， 即LSTM的层数乘以方向数量。这个方向数量是由前面介绍的bidirectional决定，如果为False,则等于1；反之等于2。\r\n",
        "  - batch：同上\r\n",
        "  - hidden_size: 隐藏层节点数\r\n",
        "- c_0： 维度形状为 (num_layers * num_directions, batch, hidden_size),各参数含义和h_0类似。\r\n",
        "\r\n",
        "当然，如果你没有传入(h_0, c_0)，那么这两个参数会默认设置为0。\r\n",
        "\r\n",
        "## 输出\r\n",
        "output, (h_n,c_n)\r\n",
        "- output： 维度和输入数据类似，只不过最后的feature部分会有点不同，即 (seq_len, batch, num_directions * hidden_size)这个输出tensor包含了LSTM模型最后一层每个time step的输出特征另外如果前面你对输入数据使用了torch.nn.utils.rnn.PackedSequence,那么输出也会做同样的操作编程packed sequence。对于unpacked情况，我们可以对输出做如下处理来对方向作分离output.view(seq_len, batch, num_directions, hidden_size), 其中前向和后向分别用0和1表示Similarly, the directions can be separated in the packed case.\r\n",
        "- h_n：(num_layers * num_directions, batch, hidden_size)，\r\n",
        "只会输出最后个time step的隐状态结果\r\n",
        "- c_n ：(num_layers * num_directions, batch, hidden_size)，只会输出最后个time step的cell状态结果（如下图所示）。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-1bOSUPmuNm"
      },
      "source": [
        "class BiLSTM(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(BiLSTM, self).__init__()\r\n",
        "        self.lstm = nn.LSTM(input_size=n_class, hidden_size=n_hidden, bidirectional=True) # 是否双向\r\n",
        "        # fc\r\n",
        "        self.fc = nn.Linear(n_hidden * 2, n_class) # *2因为双向 \r\n",
        "\r\n",
        "    def forward(self, X):\r\n",
        "        # X: [batch_size, max_len, n_class]\r\n",
        "        batch_size = X.shape[0]\r\n",
        "        input = X.transpose(0, 1)  # input : [max_len, batch_size, n_class]\r\n",
        "\r\n",
        "        hidden_state = torch.randn(1*2, batch_size, n_hidden).to(device)   # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\r\n",
        "        cell_state = torch.randn(1*2, batch_size, n_hidden).to(device)     # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\r\n",
        "\r\n",
        "        outputs, (_, _) = self.lstm(input, (hidden_state, cell_state))\r\n",
        "        outputs = outputs[-1]  # [batch_size, n_hidden * 2]\r\n",
        "        model = self.fc(outputs)  # model : [batch_size, n_class]\r\n",
        "        return model\r\n",
        "\r\n",
        "model = BiLSTM().to(device)\r\n",
        "criterion = nn.CrossEntropyLoss().to(device)\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrQsawhSsXrQ"
      },
      "source": [
        "# 训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQDOYpw6srG9",
        "outputId": "9aa49dcd-29ec-435a-bf2a-28c6082bcac8"
      },
      "source": [
        "# Training\r\n",
        "for epoch in range(10000):\r\n",
        "    for x, y in loader:\r\n",
        "      pred = model(x.to(device))\r\n",
        "      loss = criterion(pred, y.to(device))\r\n",
        "      if (epoch + 1) % 2500 == 0:\r\n",
        "          print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\r\n",
        "\r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2500 cost = 0.821938\n",
            "Epoch: 2500 cost = 0.222033\n",
            "Epoch: 2500 cost = 1.067995\n",
            "Epoch: 2500 cost = 1.481362\n",
            "Epoch: 2500 cost = 0.987236\n",
            "Epoch: 2500 cost = 0.218648\n",
            "Epoch: 2500 cost = 1.267750\n",
            "Epoch: 5000 cost = 0.742563\n",
            "Epoch: 5000 cost = 0.165926\n",
            "Epoch: 5000 cost = 0.082179\n",
            "Epoch: 5000 cost = 0.102131\n",
            "Epoch: 5000 cost = 0.344776\n",
            "Epoch: 5000 cost = 0.170287\n",
            "Epoch: 5000 cost = 0.237099\n",
            "Epoch: 7500 cost = 0.010331\n",
            "Epoch: 7500 cost = 0.248058\n",
            "Epoch: 7500 cost = 0.016673\n",
            "Epoch: 7500 cost = 0.021382\n",
            "Epoch: 7500 cost = 0.018066\n",
            "Epoch: 7500 cost = 0.255733\n",
            "Epoch: 7500 cost = 0.020288\n",
            "Epoch: 10000 cost = 0.004539\n",
            "Epoch: 10000 cost = 0.233148\n",
            "Epoch: 10000 cost = 0.001186\n",
            "Epoch: 10000 cost = 0.241349\n",
            "Epoch: 10000 cost = 0.003039\n",
            "Epoch: 10000 cost = 0.005206\n",
            "Epoch: 10000 cost = 0.001360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM7FPI2ysuQ-"
      },
      "source": [
        "# 测试"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXrTHIK2swsO",
        "outputId": "73fd2774-4d1c-4d80-e9d9-1ba4a8f3650a"
      },
      "source": [
        "# Pred\r\n",
        "predict = model(input_batch.to(device)).data.max(1, keepdim=True)[1]\r\n",
        "print(sentence)\r\n",
        "print([idx2word[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GitHub Actions makes it easy to automate all your software workflows from continuous integration and delivery to issue triage and more\n",
            "['Actions', 'makes', 'it', 'easy', 'to', 'automate', 'all', 'your', 'software', 'workflows', 'from', 'continuous', 'integration', 'and', 'delivery', 'to', 'issue', 'triage', 'and', 'more']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}