# 1 介绍

# 2 背景

# 3 模型架构

## 3.1 编码器和解码器堆栈

## 3.2 注意

### 3.2.1 缩放点-产品注意力

### 3.2.2 多头注意力

### 3.2.3 注意力在我们模型中的应用

## 3.3 位置前馈网络

## 3.4 嵌入和softmax

## 3.5 位置编码

# 4 为什么要自我注意

# 5 训练

## 5.1 培训数据和批处理

## 5.2 硬件和时间表

## 5.3 优化

## 5.4 正则

# 6 结果

## 6.1 机器翻译

## 6.2 型号变化

## 6.3 英国地区解析

# 7 结论

